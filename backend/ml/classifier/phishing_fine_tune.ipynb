{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5392ca87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8043ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install \"transformers==4.43.3\" \"datasets==2.20.0\" \"accelerate==0.33.0\" \"evaluate==0.4.2\" \"scikit-learn==1.4.2\" \"torch==2.3.1\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adbba6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch device: mps\n",
      "Splits exist? train: True val: True test: True\n"
     ]
    }
   ],
   "source": [
    "import os, numpy as np, pandas as pd, torch\n",
    "from pathlib import Path\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# call datasets\n",
    "DATA_DIR = Path(\"cleaned\")\n",
    "TRAIN_CSV = DATA_DIR/\"train_dataset.csv\"\n",
    "TEST_CSV = DATA_DIR/\"test_dataset.csv\"\n",
    "VAL_CSV = DATA_DIR/\"val_dataset.csv\"\n",
    "\n",
    "\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "ARTIFACTS = Path(\"artifacts/distilbert_phishing\")\n",
    "ARTIFACTS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "LABEL_NAMES = {0: \"Ham\", 1: \"Phishing\"}\n",
    "\n",
    "\n",
    "#  Helpful: see what compute you'll use\n",
    "device = \"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Torch device:\", device)\n",
    "\n",
    "# Optional: quick existence check; we'll assert on load next cell\n",
    "print(\"Splits exist? train:\", TRAIN_CSV.exists(), \"val:\", VAL_CSV.exists(), \"test:\", TEST_CSV.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaefb77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (4883, 2) {0: 0.826, 1: 0.174}\n",
      "val (610, 2) {0: 0.826, 1: 0.174}\n",
      "test (611, 2) {0: 0.825, 1: 0.175}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>geeee ... i miss you already, you know ? your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>i dnt wnt to tlk wid u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>haven't left yet so probably gonna be here til...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL                                               TEXT\n",
       "0      0  geeee ... i miss you already, you know ? your ...\n",
       "1      0                             i dnt wnt to tlk wid u\n",
       "2      0  haven't left yet so probably gonna be here til..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "val_df   = pd.read_csv(VAL_CSV)\n",
    "test_df  = pd.read_csv(TEST_CSV)\n",
    "\n",
    "for name, df in [(\"train\", train_df), (\"val\", val_df), (\"test\", test_df)]:\n",
    "    assert {\"TEXT\",\"LABEL\"}.issubset(df.columns), f\"{name} split missing TEXT/LABEL\"\n",
    "    assert set(df[\"LABEL\"].unique()).issubset({0,1}), f\"{name} has non-binary labels\"\n",
    "    print(name, df.shape, df[\"LABEL\"].value_counts(normalize=True).round(3).to_dict())\n",
    "\n",
    "train_df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93c8ae4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    4883.000000\n",
      "mean       82.607413\n",
      "std        59.287982\n",
      "min         2.000000\n",
      "50%        65.000000\n",
      "90%       155.000000\n",
      "95%       161.000000\n",
      "99%       276.000000\n",
      "max       910.000000\n",
      "Name: char_len, dtype: float64\n",
      "Tokenizer loaded.\n"
     ]
    }
   ],
   "source": [
    "# Length peek so you can justify MAX_LEN in your report\n",
    "train_df[\"char_len\"] = train_df[\"TEXT\"].astype(str).str.len()\n",
    "print(train_df[\"char_len\"].describe(percentiles=[.5, .9, .95, .99]))\n",
    "\n",
    "# Most SMS fit easily in 128 tokens; we’ll start there\n",
    "MAX_LEN = 192\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Build Hugging Face Datasets (Trainer likes these)\n",
    "ds = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(train_df.drop(columns=[\"char_len\"], errors=\"ignore\"), preserve_index=False),\n",
    "    \"val\":   Dataset.from_pandas(val_df, preserve_index=False),\n",
    "    \"test\":  Dataset.from_pandas(test_df, preserve_index=False),\n",
    "})\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\", use_fast=True)\n",
    "print(\"Tokenizer loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fa807d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4883/4883 [00:00<00:00, 8503.59 examples/s] \n",
      "Map: 100%|██████████| 610/610 [00:00<00:00, 19540.57 examples/s]\n",
      "Map: 100%|██████████| 611/611 [00:00<00:00, 24318.61 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 4883\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 610\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 611\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Reduce sequence length and re-tokenise\n",
    "MAX_LEN = 128\n",
    "def tokenize_batch(batch):\n",
    "    return tokenizer(batch[\"TEXT\"], padding=False, truncation=True, max_length=MAX_LEN)\n",
    "\n",
    "tokenized = ds.map(tokenize_batch, batched=True)\n",
    "tokenized = tokenized.rename_column(\"LABEL\", \"labels\")\n",
    "for split in tokenized:\n",
    "    tokenized[split] = tokenized[split].remove_columns(\n",
    "        [c for c in tokenized[split].column_names if c not in (\"input_ids\",\"attention_mask\",\"labels\")]\n",
    "    )\n",
    "tokenized.set_format(type=\"torch\")\n",
    "tokenized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b7f4685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts  : {0: 4033, 1: 850}\n",
      "Class weights : [0.6053805947303772, 2.8723528385162354]   # order matches classes: [0, 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, torch\n",
    "\n",
    "classes, counts = np.unique([int(x) for x in train_df[\"LABEL\"].values], return_counts=True)\n",
    "total = counts.sum()\n",
    "class_weights = torch.tensor(total / (len(classes) * counts), dtype=torch.float)\n",
    "\n",
    "print(\"Class counts  :\", dict(zip(classes, counts)))\n",
    "print(\"Class weights :\", class_weights.tolist(), \"  # order matches classes:\", classes.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4d79415",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/jordancroft/Documents/Documents - Jordan.’s MacBook Air/GitHub/Phishing-detector-backend/ml/classifier/.venv/lib/python3.11/site-packages/transformers/training_args.py:1540: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of 🤗 Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n",
      "  6%|▋         | 97/1530 [2:43:37<40:17:21, 101.22s/it]\n",
      "  4%|▍         | 50/1220 [01:40<34:05,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3141, 'grad_norm': 0.552915632724762, 'learning_rate': 1.918032786885246e-05, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 100/1220 [03:43<59:35,  3.19s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1126, 'grad_norm': 0.1927800476551056, 'learning_rate': 1.836065573770492e-05, 'epoch': 0.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 150/1220 [05:50<40:31,  2.27s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1426, 'grad_norm': 1.103765606880188, 'learning_rate': 1.7540983606557377e-05, 'epoch': 0.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 200/1220 [08:17<1:08:32,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1377, 'grad_norm': 0.6060847640037537, 'learning_rate': 1.6721311475409837e-05, 'epoch': 0.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 250/1220 [10:58<36:31,  2.26s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0432, 'grad_norm': 0.047016218304634094, 'learning_rate': 1.5901639344262295e-05, 'epoch': 0.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 300/1220 [12:37<34:31,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1434, 'grad_norm': 0.3174337148666382, 'learning_rate': 1.5081967213114754e-05, 'epoch': 0.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 305/1220 [12:47<29:01,  1.90s/it]\n",
      " 25%|██▌       | 305/1220 [12:58<29:01,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09538261592388153, 'eval_accuracy': 0.9885245901639345, 'eval_precision': 0.9714285714285714, 'eval_recall': 0.9622641509433962, 'eval_f1': 0.966824644549763, 'eval_roc_auc': 0.9960879005690326, 'eval_runtime': 10.6462, 'eval_samples_per_second': 57.297, 'eval_steps_per_second': 7.233, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 350/1220 [15:52<1:16:11,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0369, 'grad_norm': 0.04437772557139397, 'learning_rate': 1.4262295081967214e-05, 'epoch': 1.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 400/1220 [17:51<27:13,  1.99s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0485, 'grad_norm': 0.04577852040529251, 'learning_rate': 1.3442622950819673e-05, 'epoch': 1.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 450/1220 [19:20<17:46,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0369, 'grad_norm': 0.03798583894968033, 'learning_rate': 1.2622950819672132e-05, 'epoch': 1.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 500/1220 [20:50<24:23,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0666, 'grad_norm': 0.027329187840223312, 'learning_rate': 1.1803278688524591e-05, 'epoch': 1.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 550/1220 [22:21<20:00,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0662, 'grad_norm': 0.02846544235944748, 'learning_rate': 1.0983606557377052e-05, 'epoch': 1.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 600/1220 [23:52<21:58,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0335, 'grad_norm': 0.027946123853325844, 'learning_rate': 1.0163934426229509e-05, 'epoch': 1.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 611/1220 [24:12<15:25,  1.52s/it]\n",
      " 50%|█████     | 611/1220 [24:25<15:25,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11326508969068527, 'eval_accuracy': 0.9885245901639345, 'eval_precision': 0.9900990099009901, 'eval_recall': 0.9433962264150944, 'eval_f1': 0.966183574879227, 'eval_roc_auc': 0.9982966457023061, 'eval_runtime': 13.1382, 'eval_samples_per_second': 46.429, 'eval_steps_per_second': 5.861, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 611/1220 [24:33<24:28,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1473.3096, 'train_samples_per_second': 13.257, 'train_steps_per_second': 0.828, 'train_loss': 0.09676435241801892, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_runtime': 1473.3096,\n",
       " 'train_samples_per_second': 13.257,\n",
       " 'train_steps_per_second': 0.828,\n",
       " 'total_flos': 134099179678116.0,\n",
       " 'train_loss': 0.09676435241801892,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Clear caches & force CPU fallback ---\n",
    "import os, gc, torch\n",
    "gc.collect()\n",
    "if torch.backends.mps.is_available():\n",
    "    try:\n",
    "        torch.mps.empty_cache()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# This tells PyTorch to gracefully fall back when MPS can't allocate\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score\n",
    "\n",
    "# Fresh model; keep gradient checkpointing (saves RAM even on CPU)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**{k: v for k, v in inputs.items() if k != \"labels\"})\n",
    "        logits = outputs.get(\"logits\")\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights.to(logits.device))\n",
    "        loss = loss_fct(logits.view(-1, model.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(-1)\n",
    "    probs_pos = torch.softmax(torch.tensor(logits), dim=-1)[:, 1].numpy()\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\", pos_label=1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(labels, probs_pos)\n",
    "    except ValueError:\n",
    "        roc_auc = float(\"nan\")\n",
    "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"roc_auc\": roc_auc}\n",
    "\n",
    "# Conservative settings for CPU\n",
    "BATCH  = 8\n",
    "EPOCHS = 4            # CPU will be slower; 3–4 epochs is usually enough for DistilBERT on SMS\n",
    "LR     = 2e-5\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=str(ARTIFACTS/\"training\"),\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    learning_rate=LR,\n",
    "    per_device_train_batch_size=BATCH,\n",
    "    per_device_eval_batch_size=BATCH,\n",
    "    gradient_accumulation_steps=2,   # effective batch ~16\n",
    "    num_train_epochs=EPOCHS,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\",\n",
    "    seed=42,\n",
    "    fp16=False, bf16=False,\n",
    "    dataloader_num_workers=0,\n",
    "    eval_accumulation_steps=2,\n",
    "    no_cuda=True                   # 👈 force CPU (disables CUDA/MPS)\n",
    ")\n",
    "\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"val\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]\n",
    ")\n",
    "\n",
    "train_result = trainer.train()\n",
    "train_result.metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83095bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:10<00:00,  7.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.02986525185406208,\n",
       " 'eval_accuracy': 0.9885433715220949,\n",
       " 'eval_precision': 0.9464285714285714,\n",
       " 'eval_recall': 0.9906542056074766,\n",
       " 'eval_f1': 0.9680365296803652,\n",
       " 'eval_roc_auc': 0.9998331108144193,\n",
       " 'eval_runtime': 12.0174,\n",
       " 'eval_samples_per_second': 50.843,\n",
       " 'eval_steps_per_second': 6.407,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_metrics = trainer.evaluate(eval_dataset=tokenized[\"test\"])\n",
    "test_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7339e1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:10<00:00,  7.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Ham       1.00      0.99      0.99       504\n",
      "    Phishing       0.95      0.99      0.97       107\n",
      "\n",
      "    accuracy                           0.99       611\n",
      "   macro avg       0.97      0.99      0.98       611\n",
      "weighted avg       0.99      0.99      0.99       611\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "preds = trainer.predict(tokenized[\"test\"])\n",
    "y_true = preds.label_ids\n",
    "y_pred = preds.predictions.argmax(-1)\n",
    "print(classification_report(y_true, y_pred, target_names=[LABEL_NAMES[0], LABEL_NAMES[1]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "568664e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: /Users/jordancroft/Documents/Documents - Jordan.’s MacBook Air/GitHub/Phishing-detector-backend/ml/classifier/artifacts/distilbert_phishing\n"
     ]
    }
   ],
   "source": [
    "save_dir = ARTIFACTS\n",
    "trainer.model.save_pretrained(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "\n",
    "import json\n",
    "with open(save_dir/\"metrics_test.json\", \"w\") as f:\n",
    "    json.dump({k: float(v) for k,v in test_metrics.items()}, f, indent=2)\n",
    "\n",
    "print(\"Saved to:\", save_dir.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "389208ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "/Users/jordancroft/Documents/Documents - Jordan.’s MacBook Air/GitHub/Phishing-detector-backend/ml/classifier/.venv/lib/python3.11/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Royal Mail: Your parcel is waiting, pay £1.99 to release: http://bit.ly/xyz\n",
      " -> 1 (Phishing), prob_smishing=0.998\n",
      "\n",
      "Hey mate, are we still on for lunch tomorrow?\n",
      " -> 0 (Ham), prob_smishing=0.004\n",
      "\n",
      "URGENT: Your bank account is locked. Verify now at www.badsite.ru/login\n",
      " -> 1 (Phishing), prob_smishing=0.996\n",
      "\n",
      "Friday means one thing...SurPRIZE Guy could be calling YOU! Make sure you answer! > https://eej.at/Q6Z7Gjxw Stop http://oot.rs/BI2GAUar\n",
      " -> 1 (Phishing), prob_smishing=0.998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextClassificationPipeline\n",
    "pipe = TextClassificationPipeline(model=trainer.model, tokenizer=tokenizer, return_all_scores=True, truncation=True)\n",
    "\n",
    "for s in [\n",
    "    \"Royal Mail: Your parcel is waiting, pay £1.99 to release: http://bit.ly/xyz\",\n",
    "    \"Hey mate, are we still on for lunch tomorrow?\",\n",
    "    \"URGENT: Your bank account is locked. Verify now at www.badsite.ru/login\",\n",
    "    \"Friday means one thing...SurPRIZE Guy could be calling YOU! Make sure you answer! > https://eej.at/Q6Z7Gjxw Stop http://oot.rs/BI2GAUar\"\n",
    "]:\n",
    "    scores = pipe(s, max_length=128)[0]\n",
    "    p1 = next(x[\"score\"] for x in scores if x[\"label\"] in (\"LABEL_1\",\"Smishing\",\"1\"))\n",
    "    pred = 1 if p1 >= 0.5 else 0\n",
    "    print(f\"{s}\\n -> {pred} ({LABEL_NAMES[pred]}), prob_smishing={p1:.3f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1417b309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prob smishing: 0.998\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(REPO_ID)\n",
    "mdl = AutoModelForSequenceClassification.from_pretrained(REPO_ID)\n",
    "mdl.eval()\n",
    "\n",
    "enc = tok(\"Royal Mail: pay £1.99 to release your parcel http://bit.ly/xyz\", return_tensors=\"pt\", truncation=True, max_length=128)\n",
    "with torch.no_grad():\n",
    "    prob = torch.softmax(mdl(**enc).logits, dim=-1)[0,1].item()\n",
    "print(\"Prob smishing:\", round(prob, 3))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
